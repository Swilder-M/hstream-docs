(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{463:function(e,t,r){e.exports=r.p+"docs-assets/img/statistics.d9ed78f1.png"},530:function(e,t,r){"use strict";r.r(t);var a=r(11),s=Object(a.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"hstreamdb-release-notes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hstreamdb-release-notes"}},[e._v("#")]),e._v(" HStreamDB release notes")]),e._v(" "),a("h2",{attrs:{id:"v0-9-0-2022-07-29"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#v0-9-0-2022-07-29"}},[e._v("#")]),e._v(" v0.9.0 [2022-07-29]")]),e._v(" "),a("h3",{attrs:{id:"hstreamdb"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hstreamdb"}},[e._v("#")]),e._v(" HStreamDB")]),e._v(" "),a("h4",{attrs:{id:"highlights"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#highlights"}},[e._v("#")]),e._v(" Highlights")]),e._v(" "),a("ul",[a("li",[a("a",{attrs:{href:"#shards-in-streams"}},[e._v("Shards in Streams")])]),e._v(" "),a("li",[a("a",{attrs:{href:"#hstream-io"}},[e._v("HStream IO")])]),e._v(" "),a("li",[a("a",{attrs:{href:"#new-stream-processing-engine"}},[e._v("New Stream Processing Engine")])]),e._v(" "),a("li",[a("a",{attrs:{href:"#gossip-based-hserver-clusters"}},[e._v("Gossip-based HServer Clusters")])]),e._v(" "),a("li",[a("a",{attrs:{href:"#advertised-listeners"}},[e._v("Advertised Listeners")])]),e._v(" "),a("li",[a("a",{attrs:{href:"#improved-hstream-cli"}},[e._v("Improved HStream CLI")])]),e._v(" "),a("li",[a("a",{attrs:{href:"#monitoring-with-grafana"}},[e._v("Monitoring with Grafana")])]),e._v(" "),a("li",[a("a",{attrs:{href:"#deployment-on-k8s-with-helm"}},[e._v("Deployment on K8s with Helm")])])]),e._v(" "),a("h4",{attrs:{id:"shards-in-streams"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shards-in-streams"}},[e._v("#")]),e._v(" Shards in Streams")]),e._v(" "),a("p",[e._v("We have exposed shards in streams，which gives you the fine-grained control on data distribution in a stream and the ability of accessing data in a shard directly. you can assign each shard  a range of hashes in a stream, and for every "),a("code",[e._v("partitionKey")]),e._v(" of a record whose hash falls within a shard’s range will be stored in that shard. In particular, for now you can:")]),e._v(" "),a("ul",[a("li",[e._v("determine the initial number of shards while creating a stream")]),e._v(" "),a("li",[e._v("distribute records written to a stream among shards by partitionKey")]),e._v(" "),a("li",[e._v("access records from any shard directly from the specified position")])]),e._v(" "),a("p",[e._v("And in later releases, you can scale the stream by splitting and merging shards dynamically.")]),e._v(" "),a("h4",{attrs:{id:"hstream-io"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hstream-io"}},[e._v("#")]),e._v(" HStream IO")]),e._v(" "),a("p",[e._v("HStream IO is a builtin data integration framework for HStreamDB, composed of source connectors, sink connectors and the IO runtime. It allows interconnection with various external systems, facilitating the efficient flow of data across the whole enterprise data stack around HStreamDB and thereby unleashing the value of data more quickly.")]),e._v(" "),a("p",[e._v("In particular, this release contains the below connectors:")]),e._v(" "),a("ul",[a("li",[e._v("source connectors:\n"),a("ul",[a("li",[a("a",{attrs:{href:"https://github.com/hstreamdb/hstream-connectors/blob/main/docs/specs/sink_mysql_spec.md",target:"_blank",rel:"noopener noreferrer"}},[e._v("source-mysql"),a("OutboundLink")],1)]),e._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/hstreamdb/hstream-connectors/blob/main/docs/specs/source_postgresql_spec.md",target:"_blank",rel:"noopener noreferrer"}},[e._v("souce-postgresql"),a("OutboundLink")],1)]),e._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/hstreamdb/hstream-connectors/blob/main/docs/specs/source_sqlserver_spec.md",target:"_blank",rel:"noopener noreferrer"}},[e._v("source-sqlserver"),a("OutboundLink")],1)])])]),e._v(" "),a("li",[e._v("sink connectors:\n"),a("ul",[a("li",[a("a",{attrs:{href:"https://github.com/hstreamdb/hstream-connectors/blob/main/docs/specs/sink_mysql_spec.md",target:"_blank",rel:"noopener noreferrer"}},[e._v("sink-mysql"),a("OutboundLink")],1)]),e._v(" "),a("li",[a("a",{attrs:{href:"https://github.com/hstreamdb/hstream-connectors/blob/main/docs/specs/sink_postgresql_spec.md",target:"_blank",rel:"noopener noreferrer"}},[e._v("sink-postgresql"),a("OutboundLink")],1)])])])]),e._v(" "),a("p",[e._v("You can refer to "),a("RouterLink",{attrs:{to:"/en/latest/io/overview.html"}},[e._v("the documentation")]),e._v(" for learning more about HStream IO.")],1),e._v(" "),a("h4",{attrs:{id:"new-stream-processing-engine"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#new-stream-processing-engine"}},[e._v("#")]),e._v(" New Stream Processing Engine")]),e._v(" "),a("p",[e._v("We have rewritten the stream processing engine thoroughly in the interactive and differential style, which improves the throughput by up to 3 orders of magnitude and reduces the latency. It also supports "),a("strong",[e._v("multi-way joining")]),e._v(", "),a("strong",[e._v("subqueries")]),e._v(" and "),a("strong",[e._v("more general materialized views")]),e._v(". It is still experimental and you can refer to "),a("RouterLink",{attrs:{to:"/en/latest/guides/sql.html"}},[e._v("this guide")]),e._v(" for a quick start.")],1),e._v(" "),a("h4",{attrs:{id:"gossip-based-hserver-clusters"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#gossip-based-hserver-clusters"}},[e._v("#")]),e._v(" Gossip-based HServer Clusters")]),e._v(" "),a("p",[e._v("We refactor the hserver cluster with gossip-based membership and failure detection mainly based on "),a("a",{attrs:{href:"https://ieeexplore.ieee.org/document/1028914",target:"_blank",rel:"noopener noreferrer"}},[e._v("SWIM"),a("OutboundLink")],1),e._v(" paper, replacing the ZooKeeper-based implementation in the previous version. It will improve the scalability of the cluster and reduce dependencies on external systems.")]),e._v(" "),a("h4",{attrs:{id:"advertised-listeners"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#advertised-listeners"}},[e._v("#")]),e._v(" Advertised Listeners")]),e._v(" "),a("p",[e._v("The deployment and usage in production could involve a complex network setting. For example, if the server cluster is hosted internally, it would require an external IP address for clients to connect to the cluster. The use of docker and cloud-hosting can make the situation even more complicated. To ensure that clients from different networks can interact with the cluster, HStreamDB v0.9 provides configurations for advertised listeners. With advertised listeners configured, servers can return the corresponding address for different clients, according to the port to which the client sent the request.")]),e._v(" "),a("h4",{attrs:{id:"improved-hstream-cli"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#improved-hstream-cli"}},[e._v("#")]),e._v(" Improved HStream CLI")]),e._v(" "),a("p",[e._v("To make CLI more unified and more straightforward, we have migrated the old HStream SQL Shell and some other node management functionality to the new HStream CLI. HStream CLI currently supports operations such as starting an interacting SQL shell, sending bootstrap initiation and checking server node status. You can refer to "),a("RouterLink",{attrs:{to:"/en/latest/cli/cli.html"}},[e._v("the CLI documentation")]),e._v(" for details.")],1),e._v(" "),a("h4",{attrs:{id:"monitoring-with-grafana"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#monitoring-with-grafana"}},[e._v("#")]),e._v(" Monitoring with Grafana")]),e._v(" "),a("p",[e._v("We provide a basic monitoring solution based on Prometheus and Grafana. Metrics collected by HStreamDB will be stored in Prometheus by the exporter and shown on the Grafana board. For details, refer to "),a("RouterLink",{attrs:{to:"/en/latest/monitoring/grafana.html"}},[e._v("the documentation")]),e._v(".")],1),e._v(" "),a("h4",{attrs:{id:"deployment-on-k8s-with-helm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deployment-on-k8s-with-helm"}},[e._v("#")]),e._v(" Deployment on K8s with Helm")]),e._v(" "),a("p",[e._v("We provide a helm chart supporting deploying HStreamDB on k8s using Helm. You can refer to "),a("RouterLink",{attrs:{to:"/en/latest/deployment/deploy-helm.html"}},[e._v("the documentation")]),e._v(" for details.")],1),e._v(" "),a("h3",{attrs:{id:"java-client"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#java-client"}},[e._v("#")]),e._v(" Java Client")]),e._v(" "),a("p",[e._v("The "),a("a",{attrs:{href:"https://github.com/hstreamdb/hstreamdb-java/releases/tag/v0.9.0",target:"_blank",rel:"noopener noreferrer"}},[e._v("Java Client v0.9.0"),a("OutboundLink")],1),e._v(" has been released, which adds support for HStreamDB v0.9.")]),e._v(" "),a("h3",{attrs:{id:"golang-client"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#golang-client"}},[e._v("#")]),e._v(" Golang Client")]),e._v(" "),a("p",[e._v("The "),a("a",{attrs:{href:"https://github.com/hstreamdb/hstreamdb-go/releases/tag/v0.2.0",target:"_blank",rel:"noopener noreferrer"}},[e._v("Go Client v0.2.0"),a("OutboundLink")],1),e._v(" has been released, which adds support for HStreamDB v0.9.")]),e._v(" "),a("h3",{attrs:{id:"python-client"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#python-client"}},[e._v("#")]),e._v(" Python Client")]),e._v(" "),a("p",[e._v("The "),a("a",{attrs:{href:"https://github.com/hstreamdb/hstreamdb-py/releases/tag/v0.2.0",target:"_blank",rel:"noopener noreferrer"}},[e._v("Python Client v0.2.0"),a("OutboundLink")],1),e._v(" has been released, which adds support for HStreamDB v0.9.")]),e._v(" "),a("h2",{attrs:{id:"v0-8-0-2022-04-29"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#v0-8-0-2022-04-29"}},[e._v("#")]),e._v(" v0.8.0 [2022-04-29]")]),e._v(" "),a("h3",{attrs:{id:"hserver"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hserver"}},[e._v("#")]),e._v(" HServer")]),e._v(" "),a("h4",{attrs:{id:"new-features"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#new-features"}},[e._v("#")]),e._v(" New Features")]),e._v(" "),a("ul",[a("li",[e._v("Add "),a("RouterLink",{attrs:{to:"/en/latest/security/overview.html"}},[e._v("mutual TLS support")])],1),e._v(" "),a("li",[e._v("Add "),a("code",[e._v("maxUnackedRecords")]),e._v(" option in Subscription: The option controls the\nmaximum number of unacknowledged records allowed. When the amount of unacked\nrecords reaches the maximum setting, the server will stop sending records to\nconsumers, which can avoid the accumulation of unacked records impacting the\nperformance of the server and consumers. We suggest users adjust the option\nbased on the consumption performance of their application.")]),e._v(" "),a("li",[e._v("Add "),a("code",[e._v("backlogDuration")]),e._v(" option in Streams: the option determines how long\nHStreamDB will store the data in the stream. The data will be deleted and\nbecome inaccessible when it exceeds the time set.")]),e._v(" "),a("li",[e._v("Add "),a("code",[e._v("maxRecordSize")]),e._v(" option in Streams: Users can use the option to control the\nmaximum size of a record batch in the stream when creating a stream. If the\nrecord size exceeds the value, the server will return an error.")]),e._v(" "),a("li",[e._v("Add more metrics for HStream Server.")]),e._v(" "),a("li",[e._v("Add compression configuration for HStream Server.")])]),e._v(" "),a("h4",{attrs:{id:"enhancements"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#enhancements"}},[e._v("#")]),e._v(" Enhancements")]),e._v(" "),a("ul",[a("li",[e._v("[breaking changes] Simplify protocol, refactored codes and improve the\nperformance of the subscription")]),e._v(" "),a("li",[e._v("Optimise the implementation and improve the performance of resending")]),e._v(" "),a("li",[e._v("Improve the reading performance for the HStrore client.")]),e._v(" "),a("li",[e._v("Improve how duplicated acknowledges are handled in the subscription")]),e._v(" "),a("li",[e._v("Improve subscription deletion")]),e._v(" "),a("li",[e._v("Improve stream deletion")]),e._v(" "),a("li",[e._v("Improve the consistent hashing algorithm of the cluster")]),e._v(" "),a("li",[e._v("Improve the handling of internal exceptions for the HStream Server")]),e._v(" "),a("li",[e._v("Optimise the setup steps of the server")]),e._v(" "),a("li",[e._v("Improve the implementation of the stats module")])]),e._v(" "),a("h4",{attrs:{id:"bug-fixes"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bug-fixes"}},[e._v("#")]),e._v(" Bug fixes")]),e._v(" "),a("ul",[a("li",[e._v("Fix several memory leaks caused by grpc-haskell")]),e._v(" "),a("li",[e._v("Fix several zookeeper client issues")]),e._v(" "),a("li",[e._v("Fix the problem that the checkpoint store already exists during server\nstartup")]),e._v(" "),a("li",[e._v("Fix the inconsistent handling of the default key during the lookupStream\nprocess")]),e._v(" "),a("li",[e._v("Fix the problem of stream writing error when the initialisation of hstore\nloggroup is incompleted")]),e._v(" "),a("li",[e._v("Fix the problem that hstore client writes incorrect data")]),e._v(" "),a("li",[e._v("Fix an error in allocating to idle consumers on subscriptions")]),e._v(" "),a("li",[e._v("Fix the memory allocation problem of hstore client's "),a("code",[e._v("appendBatchBS")]),e._v(" function")]),e._v(" "),a("li",[e._v("Fix the problem of losing retransmitted data due to the unavailability of the\noriginal consumer")]),e._v(" "),a("li",[e._v("Fix the problem of data distribution caused by wrong workload sorting")])]),e._v(" "),a("h3",{attrs:{id:"java-client-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#java-client-2"}},[e._v("#")]),e._v(" Java Client")]),e._v(" "),a("h4",{attrs:{id:"new-features-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#new-features-2"}},[e._v("#")]),e._v(" New Features")]),e._v(" "),a("ul",[a("li",[e._v("Add TLS support")]),e._v(" "),a("li",[e._v("Add "),a("code",[e._v("FlowControlSetting")]),e._v(" setting for "),a("code",[e._v("BufferedProducer")])]),e._v(" "),a("li",[e._v("Add "),a("code",[e._v("maxUnackedRecords")]),e._v(" setting for subscription")]),e._v(" "),a("li",[e._v("Add "),a("code",[e._v("backlogDurantion")]),e._v(" setting for stream")]),e._v(" "),a("li",[e._v("Add force delete support for subscription")]),e._v(" "),a("li",[e._v("Add force delete support for stream")])]),e._v(" "),a("h4",{attrs:{id:"enhancements-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#enhancements-2"}},[e._v("#")]),e._v(" Enhancements")]),e._v(" "),a("ul",[a("li",[e._v("[Breaking change] Improve "),a("code",[e._v("RecordId")]),e._v(" as opaque "),a("code",[e._v("String")])]),e._v(" "),a("li",[e._v("Improve the performance of "),a("code",[e._v("BufferedProducer")])]),e._v(" "),a("li",[e._v("Improve "),a("code",[e._v("Responder")]),e._v(" with batched acknowledges for better performance")]),e._v(" "),a("li",[e._v("Improve "),a("code",[e._v("BufferedProducerBuilder")]),e._v(" to use "),a("code",[e._v("BatchSetting")]),e._v(" with unified\n"),a("code",[e._v("recordCountLimit")]),e._v(", "),a("code",[e._v("bytesCountLimit")]),e._v(", "),a("code",[e._v("ageLimit")]),e._v(" settings")]),e._v(" "),a("li",[e._v("Improve the description of API in javadoc")])]),e._v(" "),a("h4",{attrs:{id:"bug-fixes-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bug-fixes-2"}},[e._v("#")]),e._v(" Bug fixes")]),e._v(" "),a("ul",[a("li",[e._v("Fix "),a("code",[e._v("streamingFetch")]),e._v(" is not canceled when "),a("code",[e._v("Consumer")]),e._v(" is closed")]),e._v(" "),a("li",[e._v("Fix missing handling for grpc exceptions in "),a("code",[e._v("Consumer")])]),e._v(" "),a("li",[e._v("Fix the incorrect computation of accumulated record size in "),a("code",[e._v("BufferedProducer")])])]),e._v(" "),a("h3",{attrs:{id:"go-client"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#go-client"}},[e._v("#")]),e._v(" Go Client")]),e._v(" "),a("ul",[a("li",[e._v("hstream-go v0.1.0 has been released. For a more detailed introduction and usage,\nplease check the "),a("a",{attrs:{href:"https://github.com/hstreamdb/hstreamdb-go",target:"_blank",rel:"noopener noreferrer"}},[e._v("Github repository"),a("OutboundLink")],1),e._v(".")])]),e._v(" "),a("h3",{attrs:{id:"admin-server"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#admin-server"}},[e._v("#")]),e._v(" Admin Server")]),e._v(" "),a("ul",[a("li",[e._v("a new admin server has been released, see "),a("a",{attrs:{href:"https://github.com/hstreamdb/http-services",target:"_blank",rel:"noopener noreferrer"}},[e._v("Github repository"),a("OutboundLink")],1)])]),e._v(" "),a("h3",{attrs:{id:"tools"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#tools"}},[e._v("#")]),e._v(" Tools")]),e._v(" "),a("ul",[a("li",[e._v("Add "),a("a",{attrs:{href:"https://github.com/hstreamdb/bench",target:"_blank",rel:"noopener noreferrer"}},[e._v("bench tools"),a("OutboundLink")],1)]),e._v(" "),a("li",[e._v("[dev-deploy] Support limiting resources of containers")]),e._v(" "),a("li",[e._v("[dev-deploy] Add configuration to restart containers")]),e._v(" "),a("li",[e._v("[dev-deploy] Support uploading all configuration files in deploying")]),e._v(" "),a("li",[e._v("[dev-deploy] Support deployments with Prometheus Integration")])]),e._v(" "),a("h2",{attrs:{id:"v0-7-0-2022-01-28"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#v0-7-0-2022-01-28"}},[e._v("#")]),e._v(" v0.7.0 [2022-01-28]")]),e._v(" "),a("h3",{attrs:{id:"features"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#features"}},[e._v("#")]),e._v(" Features")]),e._v(" "),a("h4",{attrs:{id:"add-transparent-sharding-support"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#add-transparent-sharding-support"}},[e._v("#")]),e._v(" Add transparent sharding support")]),e._v(" "),a("p",[e._v("HStreamDB has already supported the storage and management of large-scale data\nstreams. With the newly added cluster support in the last release, we decided to\nimprove a single stream's scalability and reading/writing performance with a\ntransparent sharding strategy. In HStreamDB v0.7, every stream is spread across\nmultiple server nodes, but it appears to users that a stream with partitions is\nmanaged as an entity. Therefore, users do not need to specify the number of\nshards or any sharding logic in advance.")]),e._v(" "),a("p",[e._v("In the current implementation, each record in a stream should contain an\nordering key to specify a logical partition, and the HStream server will be\nresponsible for mapping these logical partitions to physical partitions when\nstoring data.")]),e._v(" "),a("h4",{attrs:{id:"redesign-load-balancing-with-the-consistent-hashing-algorithm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#redesign-load-balancing-with-the-consistent-hashing-algorithm"}},[e._v("#")]),e._v(" Redesign load balancing with the consistent hashing algorithm")]),e._v(" "),a("p",[e._v("We have adapted our load balancing with a consistent hashing algorithm in this\nnew release. Both write and read requests are currently allocated by the\nordering key of the record carried in the request.")]),e._v(" "),a("p",[e._v("In the previous release, our load balancing was based on the hardware usage of\nthe nodes. The main problem with this was that it relied heavily on a leader\nnode to collect it. At the same time, this policy requires the node to\ncommunicate with the leader to obtain the allocation results. Overall the past\nimplementation was too complex and inefficient. Therefore, we have\nre-implemented the load balancer, which simplifies the core algorithm and copes\nwell with redistribution when cluster members change.")]),e._v(" "),a("h4",{attrs:{id:"add-hstream-admin-tool"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#add-hstream-admin-tool"}},[e._v("#")]),e._v(" Add HStream admin tool")]),e._v(" "),a("p",[e._v("We have provided a new admin tool to facilitate the maintenance and management\nof HStreamDB. HAdmin can be used to monitor and manage the various resources of\nHStreamDB, including Stream, Subscription and Server nodes. The HStream Metrics,\npreviously embedded in the HStream SQL Shell, have been migrated to the new\nHAdmin. In short, HAdmin is for HStreamDB operators, and SQL Shell is for\nHStreamDB end-users.")]),e._v(" "),a("h4",{attrs:{id:"deployment-and-usage"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#deployment-and-usage"}},[e._v("#")]),e._v(" Deployment and usage")]),e._v(" "),a("ul",[a("li",[e._v("Support quick deployment via the script, see:\n"),a("RouterLink",{attrs:{to:"/en/latest/deployment/deploy-docker.html"}},[e._v("Manual Deployment with Docker")])],1),e._v(" "),a("li",[e._v("Support config HStreamDB with a configuration file, see:\n"),a("RouterLink",{attrs:{to:"/en/latest/reference/config.html"}},[e._v("HStreamDB Configuration")])],1),e._v(" "),a("li",[e._v("Support one-step docker-compose for quick-start:\n"),a("RouterLink",{attrs:{to:"/en/latest/start/quickstart-with-docker.html"}},[e._v("Quick Start With Docker Compose")])],1)]),e._v(" "),a("p",[a("strong",[e._v("To make use of HStreamDB v0.7, please use\n"),a("a",{attrs:{href:"https://github.com/hstreamdb/hstreamdb-java",target:"_blank",rel:"noopener noreferrer"}},[e._v("hstreamdb-java v0.7.0"),a("OutboundLink")],1),e._v(" and above")])]),e._v(" "),a("h2",{attrs:{id:"v0-6-0-2021-11-04"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#v0-6-0-2021-11-04"}},[e._v("#")]),e._v(" v0.6.0 [2021-11-04]")]),e._v(" "),a("h3",{attrs:{id:"features-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#features-2"}},[e._v("#")]),e._v(" Features")]),e._v(" "),a("h4",{attrs:{id:"add-hserver-cluster-support"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#add-hserver-cluster-support"}},[e._v("#")]),e._v(" Add HServer cluster support")]),e._v(" "),a("p",[e._v("As a cloud-native distributed streaming database, HStreamDB has adopted a\nseparate architecture for computing and storage from the beginning of design, to\nsupport the independent horizontal expansion of the computing layer and storage\nlayer. In the previous version of HStreamDB, the storage layer HStore already\nhas the ability to scale horizontally. In this release, the computing layer\nHServer will also support the cluster mode so that the HServer node of the\ncomputing layer can be expanded according to the client request and the scale of\nthe computing task.")]),e._v(" "),a("p",[e._v("HStreamDB's computing node HServer is designed to be stateless as a whole, so it\nis very suitable for rapid horizontal expansion. The HServer cluster mode of\nv0.6 mainly includes the following features:")]),e._v(" "),a("ul",[a("li",[e._v("Automatic node health detection and failure recovery")]),e._v(" "),a("li",[e._v("Scheduling and balancing client requests or computing tasks according to the\nnode load conditions")]),e._v(" "),a("li",[e._v("Support dynamic joining and exiting of nodes")])]),e._v(" "),a("h4",{attrs:{id:"add-shared-subscription-mode"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#add-shared-subscription-mode"}},[e._v("#")]),e._v(" Add shared-subscription mode")]),e._v(" "),a("p",[e._v("In the previous version, one subscription only allowed one client to consume\nsimultaneously, which limited the client's consumption capacity in the scenarios\nwith a large amount of data. Therefore, in order to support the expansion of the\nclient's consumption capacity, HStreamDB v0.6 adds a shared-subscription mode,\nwhich allows multiple clients to consume in parallel on one subscription.")]),e._v(" "),a("p",[e._v("All consumers included in the same subscription form a Consumer Group, and\nHServer will distribute data to multiple consumers in the consumer group through\na round-robin manner. The consumer group members can be dynamically changed at\nany time, and the client can join or exit the current consumer group at any\ntime.")]),e._v(" "),a("p",[e._v('HStreamDB currently supports the "at least once" consumption semantics. After\nthe client consumes each data, it needs to reply to the ACK. If the Ack of a\ncertain piece of data is not received within the timeout, HServer will\nautomatically re-deliver the data to the available consumers.')]),e._v(" "),a("p",[e._v("Members in the same consumer group share the consumption progress. HStream will\nmaintain the consumption progress according to the condition of the client's\nAck. The client can resume consumption from the previous location at any time.")]),e._v(" "),a("p",[e._v("It should be noted that the order of data is not maintained in the shared\nsubscription mode of v0.6. Subsequent shared subscriptions will support a\nkey-based distribution mode, which can support the orderly delivery of data with\nthe same key.")]),e._v(" "),a("h4",{attrs:{id:"add-statistical-function"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#add-statistical-function"}},[e._v("#")]),e._v(" Add statistical function")]),e._v(" "),a("p",[e._v("HStreamDB v0.6 also adds a basic data statistics function to support the\nstatistics of key indicators such as stream write rate and consumption rate.\nUsers can view the corresponding statistical indicators through HStream CLI, as\nshown in the figure below.")]),e._v(" "),a("p",[a("img",{attrs:{src:r(463),alt:""}})]),e._v(" "),a("h4",{attrs:{id:"add-rest-api-for-data-writing"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#add-rest-api-for-data-writing"}},[e._v("#")]),e._v(" Add REST API for data writing")]),e._v(" "),a("p",[e._v("HStreamDB v0.6 adds a REST API for writing data to HStreamDB.")])])}),[],!1,null,null,null);t.default=s.exports}}]);