(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{463:function(e,t,a){e.exports=a.p+"docs-assets/img/statistics.d9ed78f1.png"},525:function(e,t,a){"use strict";a.r(t);var r=a(11),n=Object(r.a)({},(function(){var e=this,t=e.$createElement,r=e._self._c||t;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("h1",{attrs:{id:"hstreamdb-release-notes"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#hstreamdb-release-notes"}},[e._v("#")]),e._v(" HStreamDB release notes")]),e._v(" "),r("h2",{attrs:{id:"v0-8-0-2022-04-29"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#v0-8-0-2022-04-29"}},[e._v("#")]),e._v(" v0.8.0 [2022-04-29]")]),e._v(" "),r("h3",{attrs:{id:"hserver"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#hserver"}},[e._v("#")]),e._v(" HServer")]),e._v(" "),r("h4",{attrs:{id:"new-features"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#new-features"}},[e._v("#")]),e._v(" New Features")]),e._v(" "),r("ul",[r("li",[e._v("Add "),r("RouterLink",{attrs:{to:"/en/latest/security/overview.html"}},[e._v("mutual TLS support")])],1),e._v(" "),r("li",[e._v("Add "),r("code",[e._v("maxUnackedRecords")]),e._v(" option in Subscription: The option controls the\nmaximum number of unacknowledged records allowed. When the amount of unacked\nrecords reaches the maximum setting, the server will stop sending records to\nconsumers, which can avoid the accumulation of unacked records impacting the\nperformance of the server and consumers. We suggest users adjust the option\nbased on the consumption performance of their application.")]),e._v(" "),r("li",[e._v("Add "),r("code",[e._v("backlogDuration")]),e._v(" option in Streams: the option determines how long\nHStreamDB will store the data in the stream. The data will be deleted and\nbecome inaccessible when it exceeds the time set.")]),e._v(" "),r("li",[e._v("Add "),r("code",[e._v("maxRecordSize")]),e._v(" option in Streams: Users can use the option to control the\nmaximum size of a record batch in the stream when creating a stream. If the\nrecord size exceeds the value, the server will return an error.")]),e._v(" "),r("li",[e._v("Add more metrics for HStream Server.")]),e._v(" "),r("li",[e._v("Add compression configuration for HStream Server.")])]),e._v(" "),r("h4",{attrs:{id:"enhancements"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#enhancements"}},[e._v("#")]),e._v(" Enhancements")]),e._v(" "),r("ul",[r("li",[e._v("[breaking changes] Simplify protocol, refactored codes and improve the\nperformance of the subscription")]),e._v(" "),r("li",[e._v("Optimise the implementation and improve the performance of resending")]),e._v(" "),r("li",[e._v("Improve the reading performance for the HStrore client.")]),e._v(" "),r("li",[e._v("Improve how duplicated acknowledges are handled in the subscription")]),e._v(" "),r("li",[e._v("Improve subscription deletion")]),e._v(" "),r("li",[e._v("Improve stream deletion")]),e._v(" "),r("li",[e._v("Improve the consistent hashing algorithm of the cluster")]),e._v(" "),r("li",[e._v("Improve the handling of internal exceptions for the HStream Server")]),e._v(" "),r("li",[e._v("Optimise the setup steps of the server")]),e._v(" "),r("li",[e._v("Improve the implementation of the stats module")])]),e._v(" "),r("h4",{attrs:{id:"bug-fixes"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#bug-fixes"}},[e._v("#")]),e._v(" Bug fixes")]),e._v(" "),r("ul",[r("li",[e._v("Fix several memory leaks caused by grpc-haskell")]),e._v(" "),r("li",[e._v("Fix several zookeeper client issues")]),e._v(" "),r("li",[e._v("Fix the problem that the checkpoint store already exists during server\nstartup")]),e._v(" "),r("li",[e._v("Fix the inconsistent handling of the default key during the lookupStream\nprocess")]),e._v(" "),r("li",[e._v("Fix the problem of stream writing error when the initialisation of hstore\nloggroup is incompleted")]),e._v(" "),r("li",[e._v("Fix the problem that hstore client writes incorrect data")]),e._v(" "),r("li",[e._v("Fix an error in allocating to idle consumers on subscriptions")]),e._v(" "),r("li",[e._v("Fix the memory allocation problem of hstore client's "),r("code",[e._v("appendBatchBS")]),e._v(" function")]),e._v(" "),r("li",[e._v("Fix the problem of losing retransmitted data due to the unavailability of the\noriginal consumer")]),e._v(" "),r("li",[e._v("Fix the problem of data distribution caused by wrong workload sorting")])]),e._v(" "),r("h3",{attrs:{id:"java-client"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#java-client"}},[e._v("#")]),e._v(" Java Client")]),e._v(" "),r("h4",{attrs:{id:"new-features-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#new-features-2"}},[e._v("#")]),e._v(" New Features")]),e._v(" "),r("ul",[r("li",[e._v("Add TLS support")]),e._v(" "),r("li",[e._v("Add "),r("code",[e._v("FlowControlSetting")]),e._v(" setting for "),r("code",[e._v("BufferedProducer")])]),e._v(" "),r("li",[e._v("Add "),r("code",[e._v("maxUnackedRecords")]),e._v(" setting for subscription")]),e._v(" "),r("li",[e._v("Add "),r("code",[e._v("backlogDurantion")]),e._v(" setting for stream")]),e._v(" "),r("li",[e._v("Add force delete support for subscription")]),e._v(" "),r("li",[e._v("Add force delete support for stream")])]),e._v(" "),r("h4",{attrs:{id:"enhancements-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#enhancements-2"}},[e._v("#")]),e._v(" Enhancements")]),e._v(" "),r("ul",[r("li",[e._v("[Breaking change] Improve "),r("code",[e._v("RecordId")]),e._v(" as opaque "),r("code",[e._v("String")])]),e._v(" "),r("li",[e._v("Improve the performance of "),r("code",[e._v("BufferedProducer")])]),e._v(" "),r("li",[e._v("Improve "),r("code",[e._v("Responder")]),e._v(" with batched acknowledges for better performance")]),e._v(" "),r("li",[e._v("Improve "),r("code",[e._v("BufferedProducerBuilder")]),e._v(" to use "),r("code",[e._v("BatchSetting")]),e._v(" with unified\n"),r("code",[e._v("recordCountLimit")]),e._v(", "),r("code",[e._v("bytesCountLimit")]),e._v(", "),r("code",[e._v("ageLimit")]),e._v(" settings")]),e._v(" "),r("li",[e._v("Improve the description of API in javadoc")])]),e._v(" "),r("h4",{attrs:{id:"bug-fixes-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#bug-fixes-2"}},[e._v("#")]),e._v(" Bug fixes")]),e._v(" "),r("ul",[r("li",[e._v("Fix "),r("code",[e._v("streamingFetch")]),e._v(" is not canceled when "),r("code",[e._v("Consumer")]),e._v(" is closed")]),e._v(" "),r("li",[e._v("Fix missing handling for grpc exceptions in "),r("code",[e._v("Consumer")])]),e._v(" "),r("li",[e._v("Fix the incorrect computation of accumulated record size in "),r("code",[e._v("BufferedProducer")])])]),e._v(" "),r("h3",{attrs:{id:"go-client"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#go-client"}},[e._v("#")]),e._v(" Go Client")]),e._v(" "),r("ul",[r("li",[e._v("hstream-go v0.1.0 has been released. For a more detailed introduction and usage,\nplease check the "),r("a",{attrs:{href:"https://github.com/hstreamdb/hstreamdb-go",target:"_blank",rel:"noopener noreferrer"}},[e._v("Github repository"),r("OutboundLink")],1),e._v(".")])]),e._v(" "),r("h3",{attrs:{id:"admin-server"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#admin-server"}},[e._v("#")]),e._v(" Admin Server")]),e._v(" "),r("ul",[r("li",[e._v("a new admin server has been released, see "),r("a",{attrs:{href:"https://github.com/hstreamdb/http-services",target:"_blank",rel:"noopener noreferrer"}},[e._v("Github repository"),r("OutboundLink")],1)])]),e._v(" "),r("h3",{attrs:{id:"tools"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#tools"}},[e._v("#")]),e._v(" Tools")]),e._v(" "),r("ul",[r("li",[e._v("Add "),r("a",{attrs:{href:"https://github.com/hstreamdb/bench",target:"_blank",rel:"noopener noreferrer"}},[e._v("bench tools"),r("OutboundLink")],1)]),e._v(" "),r("li",[e._v("[dev-deploy] Support limiting resources of containers")]),e._v(" "),r("li",[e._v("[dev-deploy] Add configuration to restart containers")]),e._v(" "),r("li",[e._v("[dev-deploy] Support uploading all configuration files in deploying")]),e._v(" "),r("li",[e._v("[dev-deploy] Support deployments with Prometheus Integration")])]),e._v(" "),r("h2",{attrs:{id:"v0-7-0-2022-01-28"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#v0-7-0-2022-01-28"}},[e._v("#")]),e._v(" v0.7.0 [2022-01-28]")]),e._v(" "),r("h3",{attrs:{id:"features"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#features"}},[e._v("#")]),e._v(" Features")]),e._v(" "),r("h4",{attrs:{id:"add-transparent-sharding-support"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#add-transparent-sharding-support"}},[e._v("#")]),e._v(" Add transparent sharding support")]),e._v(" "),r("p",[e._v("HStreamDB has already supported the storage and management of large-scale data\nstreams. With the newly added cluster support in the last release, we decided to\nimprove a single stream's scalability and reading/writing performance with a\ntransparent sharding strategy. In HStreamDB v0.7, every stream is spread across\nmultiple server nodes, but it appears to users that a stream with partitions is\nmanaged as an entity. Therefore, users do not need to specify the number of\nshards or any sharding logic in advance.")]),e._v(" "),r("p",[e._v("In the current implementation, each record in a stream should contain an\nordering key to specify a logical partition, and the HStream server will be\nresponsible for mapping these logical partitions to physical partitions when\nstoring data.")]),e._v(" "),r("h4",{attrs:{id:"redesign-load-balancing-with-the-consistent-hashing-algorithm"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#redesign-load-balancing-with-the-consistent-hashing-algorithm"}},[e._v("#")]),e._v(" Redesign load balancing with the consistent hashing algorithm")]),e._v(" "),r("p",[e._v("We have adapted our load balancing with a consistent hashing algorithm in this\nnew release. Both write and read requests are currently allocated by the\nordering key of the record carried in the request.")]),e._v(" "),r("p",[e._v("In the previous release, our load balancing was based on the hardware usage of\nthe nodes. The main problem with this was that it relied heavily on a leader\nnode to collect it. At the same time, this policy requires the node to\ncommunicate with the leader to obtain the allocation results. Overall the past\nimplementation was too complex and inefficient. Therefore, we have\nre-implemented the load balancer, which simplifies the core algorithm and copes\nwell with redistribution when cluster members change.")]),e._v(" "),r("h4",{attrs:{id:"add-hstream-admin-tool"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#add-hstream-admin-tool"}},[e._v("#")]),e._v(" Add HStream admin tool")]),e._v(" "),r("p",[e._v("We have provided a new admin tool to facilitate the maintenance and management\nof HStreamDB. HAdmin can be used to monitor and manage the various resources of\nHStreamDB, including Stream, Subscription and Server nodes. The HStream Metrics,\npreviously embedded in the HStream SQL Shell, have been migrated to the new\nHAdmin. In short, HAdmin is for HStreamDB operators, and SQL Shell is for\nHStreamDB end-users.")]),e._v(" "),r("h4",{attrs:{id:"deployment-and-usage"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#deployment-and-usage"}},[e._v("#")]),e._v(" Deployment and usage")]),e._v(" "),r("ul",[r("li",[e._v("Support quick deployment via the script, see:\n"),r("RouterLink",{attrs:{to:"/en/latest/deployment/deploy-docker.html"}},[e._v("Manual Deployment with Docker")])],1),e._v(" "),r("li",[e._v("Support config HStreamDB with a configuration file, see:\n"),r("RouterLink",{attrs:{to:"/en/latest/reference/config.html"}},[e._v("HStreamDB Configuration")])],1),e._v(" "),r("li",[e._v("Support one-step docker-compose for quick-start:\n"),r("RouterLink",{attrs:{to:"/en/latest/start/quickstart-with-docker.html"}},[e._v("Quick Start With Docker Compose")])],1)]),e._v(" "),r("p",[r("strong",[e._v("To make use of HStreamDB v0.7, please use\n"),r("a",{attrs:{href:"https://github.com/hstreamdb/hstreamdb-java",target:"_blank",rel:"noopener noreferrer"}},[e._v("hstreamdb-java v0.7.0"),r("OutboundLink")],1),e._v(" and above")])]),e._v(" "),r("h2",{attrs:{id:"v0-6-0-2021-11-04"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#v0-6-0-2021-11-04"}},[e._v("#")]),e._v(" v0.6.0 [2021-11-04]")]),e._v(" "),r("h3",{attrs:{id:"features-2"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#features-2"}},[e._v("#")]),e._v(" Features")]),e._v(" "),r("h4",{attrs:{id:"add-hserver-cluster-support"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#add-hserver-cluster-support"}},[e._v("#")]),e._v(" Add HServer cluster support")]),e._v(" "),r("p",[e._v("As a cloud-native distributed streaming database, HStreamDB has adopted a\nseparate architecture for computing and storage from the beginning of design, to\nsupport the independent horizontal expansion of the computing layer and storage\nlayer. In the previous version of HStreamDB, the storage layer HStore already\nhas the ability to scale horizontally. In this release, the computing layer\nHServer will also support the cluster mode so that the HServer node of the\ncomputing layer can be expanded according to the client request and the scale of\nthe computing task.")]),e._v(" "),r("p",[e._v("HStreamDB's computing node HServer is designed to be stateless as a whole, so it\nis very suitable for rapid horizontal expansion. The HServer cluster mode of\nv0.6 mainly includes the following features:")]),e._v(" "),r("ul",[r("li",[e._v("Automatic node health detection and failure recovery")]),e._v(" "),r("li",[e._v("Scheduling and balancing client requests or computing tasks according to the\nnode load conditions")]),e._v(" "),r("li",[e._v("Support dynamic joining and exiting of nodes")])]),e._v(" "),r("h4",{attrs:{id:"add-shared-subscription-mode"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#add-shared-subscription-mode"}},[e._v("#")]),e._v(" Add shared-subscription mode")]),e._v(" "),r("p",[e._v("In the previous version, one subscription only allowed one client to consume\nsimultaneously, which limited the client's consumption capacity in the scenarios\nwith a large amount of data. Therefore, in order to support the expansion of the\nclient's consumption capacity, HStreamDB v0.6 adds a shared-subscription mode,\nwhich allows multiple clients to consume in parallel on one subscription.")]),e._v(" "),r("p",[e._v("All consumers included in the same subscription form a Consumer Group, and\nHServer will distribute data to multiple consumers in the consumer group through\na round-robin manner. The consumer group members can be dynamically changed at\nany time, and the client can join or exit the current consumer group at any\ntime.")]),e._v(" "),r("p",[e._v('HStreamDB currently supports the "at least once" consumption semantics. After\nthe client consumes each data, it needs to reply to the ACK. If the Ack of a\ncertain piece of data is not received within the timeout, HServer will\nautomatically re-deliver the data to the available consumers.')]),e._v(" "),r("p",[e._v("Members in the same consumer group share the consumption progress. HStream will\nmaintain the consumption progress according to the condition of the client's\nAck. The client can resume consumption from the previous location at any time.")]),e._v(" "),r("p",[e._v("It should be noted that the order of data is not maintained in the shared\nsubscription mode of v0.6. Subsequent shared subscriptions will support a\nkey-based distribution mode, which can support the orderly delivery of data with\nthe same key.")]),e._v(" "),r("h4",{attrs:{id:"add-statistical-function"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#add-statistical-function"}},[e._v("#")]),e._v(" Add statistical function")]),e._v(" "),r("p",[e._v("HStreamDB v0.6 also adds a basic data statistics function to support the\nstatistics of key indicators such as stream write rate and consumption rate.\nUsers can view the corresponding statistical indicators through HStream CLI, as\nshown in the figure below.")]),e._v(" "),r("p",[r("img",{attrs:{src:a(463),alt:""}})]),e._v(" "),r("h4",{attrs:{id:"add-rest-api-for-data-writing"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#add-rest-api-for-data-writing"}},[e._v("#")]),e._v(" Add REST API for data writing")]),e._v(" "),r("p",[e._v("HStreamDB v0.6 adds a REST API for writing data to HStreamDB.")])])}),[],!1,null,null,null);t.default=n.exports}}]);